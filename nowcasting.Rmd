---
title: "Proyecto Final"
output:
  html_document:
    theme: united
    highlight: tango
  pdf_document: default
---

```{r include=FALSE}
library(bsts)
library(ggplot2)
library(zoo)
library(dplyr)
library(tidyr)
library(tsibble)
library(feasts)
library(ggrepel)
set.seed(012)
```

#### Metodos Analíticos 2023

> -   Vianey Galindo Añel
> -   Alberto Fuentes Chavarría

### Predicción inmediata para la venta de casas usando la paquetería BSTS de R y búsquedas de Google.

## Contexto

::: {align="justify"}
La predicción inmediata *(nowcasting)* es una técnica poderosa que permite estimar y predecir variables económicas y sociales en tiempo real, proporcionando información valiosa para la toma de decisiones rápidas y fundamentadas. Utilizar *nowcasting* permite contar con estimaciones tempranas de variables que generalmente se conocen con cierto desfase o retraso considerable.

El *nowcasting* se vale de información de variables relacionadas con la variable objetivo y de las cuales si contamos con información de manera oportuna.

Esta técnica tiene aplicaciones en diversos ámbitos como:
- Economía: Cálculo del PIB, inflación, desempleo.
- Finanzas: Precios de acciones, bonos, divisas.
- Salud: Propagación de enfermedades.
- Medio ambiente: Clima, calidad del aire.
- Retail: Demanda del consumidor.

<br>

## Objetivo

El objetivo del presente trabajo es analizar el comportamiento de la serie temporal de datos con cifras de ventas de casas nuevas y ajustar un modelo bayesiano de series de tiempo (BSTS) para hacer predicciones inmediatas y selección de variables explicativas, el cual contemple los siguientes aspectos:

-Un módulo de series de tiempo que capture la tendencia general y los patrones estacionales en los datos.

-Un componente de regresión que permita la incorporación de datos exógenos (en nuestro caso, datos de Google Trends).

Nos interesa hacer métodos iniciales sin el componente de regresión y compararlo con otros que si lo tengan para así porder comparar y tomar una decisión sobre el aporte que tienen los datos exógenos.

## Metodología

#### Obtención y pre-procesamiento de datos

Los datos empleados para el análisis se obtuvieron de las estadísticas publicadas mensualmente por la Oficina del Censo de EE. UU. (The US Census Bureau) y el Departamento de Vivienda y Desarrollo Urbano de EE. UU. (The US Department of Housing and Urban Development), sobre el mercado de la vivienda al cierre de cada mes. Los datos incluyen cifras sobre 'Casas nuevas vendidas y por venta' para el periodo que comprende desde enero del año 2004 hasta septiembre de 2012, se presentan de forma mensual y en unidades de miles.

<br>

## Serie de Tiempo

#### Visualización de viviendas nuevas vendidas

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
# lectura de datos 
housing <- read.csv("./data/HSN1FNSA.csv", header = T) |> 
  mutate(DATE = as.Date(DATE)) |> 
  mutate(DATE = yearmonth(DATE))|> 
  as_tsibble(index=DATE)
# mean(housing$HSN1FNSA) #57.94286
# sd(housing$HSN1FNSA)   #32.9728 
# xi = zi*sd + mu

ggplot(housing, aes(x=DATE,y=HSN1FNSA, group = 1))+geom_line(size=1)+
  xlab("Fecha")+
  ylab("Viviendas en miles")+
  theme_bw()


```

#### Tendencia

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
ggplot(housing, aes(x=DATE,y=HSN1FNSA, group = 1))+geom_line(size=1, colour="darkgray")+
  xlab("Fecha")+
  ylab("Viviendas en miles")+
  geom_smooth(se = FALSE, span = 0.5)+
  theme_bw()
```

Gráficando la serie de ventas de casas nuevas, observamos que alcanzó su punto máximo en marzo de 2005.

-   Su principal característica es la tendencia decreciente.

-   Esta serie también tiene indicios de estacionalidad mensual, periodo 12.

#### Estacionalidad (mensual)

En la siguiente gráfica tomamos los datos de la serie para comparar su comportamiento por año y ver si se cumple la estacionalidad que se sospecha:
```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=7, fig.margin = TRUE}
  gg_season(housing, HSN1FNSA, labels="both", labels_right_nudge=4, size=1, labels_repel = TRUE) + 
  xlab("Mes")+
  ylab("Viviendas en miles")+
  theme_bw()
```

Podemos observar un patrón fuerte de estacionalidad en los primeros tres años. Con el mes de Marzo con un pico de ventas importante, una disminución el resto del año con un ligero repunte en el mes de Octubre. A partir de Abril 2007 se observa un comportamiento atípico relacionado a la crisis sufrida en el mercado americano. Para los años 2011 y 2012 podemos observar nuevamente una ligera estacionalidad mensual.

#### Autocorrelación

También es de nuestro interés ver analizar las gráficas de autocorrelación y autocorrelación parcial para ver los efectos directos de los datos pasados.

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
# y <- ts(housing$HSN1FNSA, freq = 12, start = c(2004,1))
#
# afc(y)
# class(y)

feasts::ACF(housing, HSN1FNSA, lag_max = 30) |> autoplot()
```

Esta ACF muestra correlaciones totales, capturando tanto el efecto de la tendencia como la estacionalidad. Al tener una tendencia tan fuerte como vimos en las gráficas anteriores, tiene sentido que la serie tenga una correlación muy alta con los meses inmediatos anteriores. En otras palabras, el aspecto de la tendencia está dominando nuestra gráfica ACF.

También podríamos preguntarnos sobre las correlaciones parciales, es decir, podríamos interesarnos en ver el efecto que tienen las ventas del mes de junio de 2012 en las ventas de septiembre de 2012, controlando las ventas de julio y agosto de 2012. 

<center>![](./pacf.png)</center>

Es decir, buscamos la correlación directa, bloqueando la correlación que ocurre a través de otros meses intermedios.

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
feasts::PACF(housing, HSN1FNSA, lag_max = 30) |> autoplot() 
```

Cuando condicionamos meses intermedios en nuestra serie, prácticamente todas las correlaciones parciales se encuentran dentro de los intervalos del 95% (estos intervalos consideran la hipótesis de que los valores de la serie no tienen autocorrelación). Estos datos podrían corresponder a un modelo subyacente autoregresivo de orden 1.

## Modelo bayesiano estructural de series de tiempo (BSTS)

Los modelos bayesianos estructurales de series de tiempo son modelos utilizados para la selección de covariables, forecasting, nowcasting, la inferencia del impacto causal y otras aplicaciones. La representación estado-espacio considerada para el modelo que se busca implementar es la siguiente:

<center>![](./Picture1.jpg)</center>

Donde $\mu_t$ representa la el nivel con un parámetro de tendencia, $\tau_t$ la estacionalidad y $\beta^Tx_t$ el componente de regresión  que multiplica las variables regresoras $x_t$. La ecuación del nivel que incluyela es parecida a la ecuación de nivel de un modelo local pero con un término adicional, $\delta_t$, que denota la cantidad extra de $\mu$ cuando damos un paso $t \rightarrow t+1$ y puede interpretarse como la pendiente de la tendencia lineal local multiplicada por $\Delta t$ que siempre es igual a 1. En general un modelo con tendencia lineal local es un modelo mejor que el modelo de nivel local si se cree que la serie de tiempo tiene una tendencia en una dirección particular y desea que los pronósticos futuros reflejen un aumento (o disminución) continuo visto en observaciones recientes. Mientras que el modelo de nivel local basa los pronósticos en torno al valor promedio de las observaciones recientes, el modelo de tendencia lineal local también agrega pendientes ascendentes o descendentes recientes. 

La mejor forma de comprender el componente estacional $\tau_t$ es verlo como una regresión con variables estacionales dummies. En nuestro caso tenemos periodos mensuales, de manera que S=12. El modelo de estados estacional incluye las 12 variables dummies pero restringe sus coeficientes para que sumen cero.

#### Construcción de Modelos

Estamos interesados en hacer pronósticos a corto plazo sobre el número de viviendas vendidas en EEUU. Para ello vamos a definir varios modelos, para posteriormente comparar las predicciones a un paso de cada modelo y porder elegir el mejor.

-   **Modelo 1:** Modelo con nivel local y tendencia

-   **Modelo 2:** Modelo con nivel local, tendencia y estacionalidad(12 meses)

-   **Modelo 3:** Modelo con nivel local, tendencia, estacionalidad y componente autoregresiva AR(12)

-   **Modelo 4:** Modelo con nivel local tendencia, estacionalidad y predictores (Google Trends)

Nota: Se decide dejar los últimos 3 meses de nuestra base de datos como "datos nuevos", para realizar nuestro Nowcasting con el modelo que toma en cuenta las covariables, donde se tienee información de estas  regresoras para tener otro tipo de criterio sobre su desempeño. 

#### Modelo 1

El primer modelo es nuestro modelo *base* el cual únicamente contempla la tendencia de los datos.

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}

# Modelo 1
#para los estados con tendencia
data_housing <- read.csv("./data/HSN1FNSA_correlate.csv")

new_data <- tail(data_housing, 3)
data_housing <- tail(data_housing, 102)
ss1 <- AddLocalLinearTrend(list(), data_housing$HSN1FNSA)
model1 <- bsts(data_housing$HSN1FNSA,
               state.specification = ss1,
               niter = 4000,
               ping = 0)

#plot(model1)
plot(model1, "components", main = "Contribución del componente")

pred1 <- predict(model1, horizon = 3, burn=400)
plot(pred1, plot.original = 102, main = "Predicción de 3 meses")
```

#### Modelo 2

Para el segundo modelo adicional a la tendencia se agrega el modulo de estacionalidad mensual.

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
#Modelo 2
ss2 <- AddSeasonal(ss1, data_housing$HSN1FNSA,nseasons=12)
model2 <- bsts(data_housing$HSN1FNSA,
               state.specification = ss2,
               niter = 4000,
               ping = 0)

#plot(model2)
plot(model2, "components", main = "Contribución del componente")

pred2 <- predict(model2, horizon = 3, burn=400)
plot(pred2, plot.original = 102, main = "Predicción de 3 meses")
 
```

Algo que es importante notar en esta gáfica de predicción a un paso es que hay mejoría en comparación con el modelo anterior, el intervalo de confianza se hace más pequeño para las predicciones de los últimos 3 meses.

#### Modelo 3

El tercer modelo adicional a los elementos anteriores una componente autorregresiva de nivel 12 AR(12). Vale la pena mencionar que este modelo que incluye AR(12) se hizo posteriormente a un modelo con AR(1), que se diseñó siguiendo la lógica de los resultados obtenidos con las gráficas de autocorrelación y autocorrelación parcial, que decidimos descaratr porque este modelo no agregaba información a los dos modelos previos. 

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
#Modelo3
ss3 <- AddAr(ss2, data_housing$HSN1FNSA, lags = 12)
model3 <- bsts(data_housing$HSN1FNSA,
               state.specification = ss3,
               niter = 3000, seed=12,
               ping = 0)

#plot(model3)
plot(model3, "components", main = "Contribución del componente")

pred3 <- predict(model3, horizon = 3, burn=400)
plot(pred3, plot.original = 102, main = "Predicción de 3 meses")
```

Y nuevamente obtenemos un modelo con predicciones a un paso más precisas.

Comparamos los tres modelos anteriores con la siguiente gráfica donde vemos los errores acumulados para cada modelo. El tercer modelo es claramente el de mejor desempeño. Cabe resaltar que el modelo que contempla tendencia y estacionalidad tiene peor desempeño al llegar a 80 meses. Esto se puede explicar ya que como veiamos la estacionalidad (mensual) esta marcada pero no en todos los años, mientras que la tendencia decreciente ocurría la mayor parte del tiempo.

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
#Comparación 3 modelos
CompareBstsModels(list("trend" = model1,
                       "trend + season" = model2,
                       "trend + season + AR12" = model3),
                  colors = c("black", "red", "blue"),burn=400)
```



Para la construcción de los siguientes dos modelos utilizaremos información obtenida a través de las herramientas de Google (Google Correlate y Google Trends). Se utilizó un archivo que contenía la serie de tiempo de ventas de casas como input para Google Correlate y el output es otra serie con las 100 búsquedas de Google más correlacionadas con nuestros datos y el índice para cada uno de los meses correspondientes. Se depuran variables del output que de acuerdo a criterio experto no tiene sentido incluirlas (por ejemplo, "tahitian noni house", "exhaust sound"...). Las cifras en esta base obtenidas con la herramienta de Google están estandarizadas por lo que se estandarizó nuestra variable objetivo y se unieron las dos bases de acuerdo a la fecha . El resultados es una sola base con 105 renglones (observaciones) y 71 columnas (fecha, ventas de casas y 69 covariables).


<center>![](./google_corr.png)</center>

```{r}
#data_housing <- read.csv("./data/HSN1FNSA_correlate.csv")
head(data_housing |> select(1:10))
```

#### Modelo 4

**Selección de variables**

Es recomendable hacer selección de variables si se está buscando entre una cantidad relativamente grande de regresores, como en nuestro caso. Con el software de BSTS se utiliza una inicialización de spike-slab, que asigna a todos los coeficientes una probabilidad de ser 0. Gracias al muestreo de las posteriores se puede contar con una probabilidad de inclusión en el modelo para cada variable.

Para comprender mejor el valor de los datos de Google Trends, ajustamos un modelo de serie de tiempo que incluye tendencia, estacionalidad y toma en cuenta el componente de regresión antes mencionado.

Cabe mencionar que el modelo con los datos de Google Trends continúa acumulando errores a un ritmo más o menos constante. Esto es digno de mención, ya que es ampliamente reconocido que el problema más desafiante en el pronóstico de series de tiempo económicas está en predecir los "puntos de inflexión". En este modelo, el componente de regresión explica una cantidad sustancial de variación de nuestros datos.

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
#por default busca sólo tomar una variable
model4 <- bsts( HSN1FNSA~ .,
               state.specification = ss2,
               niter = 3000,
               ping = 0,
               data = select(data_housing, -1),
               expected.model.size = 5)

#plot(model4)
plot(model4, "components", main = "Contribución del componente")

pred4 <- predict(model4, horizon = 3, newdata = new_data, burn=400)
plot(pred4, plot.original = 102, main = "Predicción de 3 meses")

```

<br> Nos interesa ver cuales fueron las variables seleccionadas para el modelo 4. La siguiente gráfica muestra las probabilidades posteriores de inclusión las variables que tienen las más altas probabilidades

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
plot(model4, "coefficients", inc=.15, main = "Top de variables seleccionadas para el modelo 4")
```

Las barras están coloreadas según la probabilidad de que el coeficiente sea positivo. Las barras blancas corresponden a coeficientes positivos y las negras a coeficientes negativos.

Para determinar si realmente existe una mejora utilizando los datos de Google, comparamos los tres modelos anteriores con el nuevo modelo. Al observar la gráfica de errores acumulados de predicción a un paso, podemos ver que el modelo que incluye las variables explicativas muestra un mejor rendimiento a partir del mes 18 ya que los errores acumulados para este crecen de manera más lenta en comparación con los otros modelos.

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=8, fig.margin = TRUE}
CompareBstsModels(list("Trend" = model1,
                       "Trend + Season" = model2,
                       "Trend + Season + AR(12)" = model3,
                       "Trend + Season + Vars" = model4),
                  colors = c("black", "red", "blue","purple"), burn=400)
```

<br> En esta gráfica se puede ver que para Mayo 2007 que es cuando empieza una tendecia a la baja más notable, y que corresponde al periodo 29, la diferencia de los errores acumulados se va haciendo más grande entre los modelos que no incluyen variables contra el que si.

La gráfica en donde se compara los estados posteriores en el modelo 4 con los datos reales estandarizados del número de ventas es:
```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
plot(model4, main = "Datos actuales vs Datos ajustados")
```


Y por último, si quisieramos verificar si los residuos para el último modelo se pueden ver como ruido blanco podemos verlo con la siguiente gráfica ACF. Este es un buen indicativo de que se sumple nuestro supuesto inicial sobre los errores.

```{r echo = FALSE, warning=FALSE, fig.width=10, fig.height=5, fig.margin = TRUE}
pred_errors_tbl <- bsts.prediction.errors(model4)$in.sample |> 
  t() |> as_tibble() |>
  mutate(t = 1:102) |> 
  pivot_longer(-c(t), names_to = "sim", values_to = "valor") |>
  group_by(t) |> 
  summarise(valor = mean(valor)) |> 
  as_tsibble(index = t)

ACF(pred_errors_tbl, valor, lag_max = 20) |> 
  autoplot() + ylim(c(-1,1))
```

<br>

## Conclusiones

-   La aplicación de técnicas de nowcasting resultó útil para predecir el número de viviendas vendidas en un corto plazo.
-   La incorporación de información de Google Trends en nuestros modelos demostró mejorar el nivel de precisión en las predicciones.
-   Existen métodos robustos, como el enfoque spike-slab, que permiten seleccionar las variables más relevantes de un conjunto amplio.
-   Aunque disponemos de herramientas poderosas, como Google Correlate y Google Trends, y de metodologías como spike-slab para filtrar variables, aún es necesario utilizar el criterio de un experto para eliminar aquellas variables que no tienen sentido en el contexto (ej. house pricing vs exhaust sound).

## Referencias

-   Banbura, Marta and Giannone, Domenico and Reichlin, Lucrezia, Nowcasting (Noviembre 30, 2010). ECB Working Paper No. 1275, Disponible en SSRN: <https://ssrn.com/abstract=1717887> or <http://dx.doi.org/10.2139/ssrn.1717887>
-   Choi, H. and Varian, H. (2009). Predicting the present with Google Trends. Tech. rep., Google.
-   Choi, H. and Varian, H. (2012). Predicting the present with Google Trends. Economic Record 88, 2--9.
-   U.S. Census Bureau and U.S. Department of Housing and Urban Development, New One Family Houses Sold: United States [HSN1FNSA], retrieved from FRED, Federal Reserve Bank of St. Louis; <https://fred.stlouisfed.org/series/HSN1FNSA>
:::
